{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patrones.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3up1gTZP2YAO",
        "colab_type": "code",
        "outputId": "6f08c504-b7dc-4046-bd34-9a71002baf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTCqU3yQ2soD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \"gdrive/My Drive/Colab Notebooks/Patrones/denoised_testing.zip\"\n",
        "#!unzip \"gdrive/My Drive/Colab Notebooks/Patrones/denoised_training.zip\"\n",
        "#!unzip \"gdrive/My Drive/Colab Notebooks/Patrones/denoised_val.zip\" # 10% of training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2foR4E97527l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras.utils import Sequence, multi_gpu_model\n",
        "from keras.layers import Input, Dense, LeakyReLU, Concatenate, Lambda, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM9LF-ub3duR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, cosine = True, alpha = 0.2):\n",
        "    embedding_size = K.int_shape(y_pred)[-1] // 3\n",
        "    ind = int(embedding_size * 2)\n",
        "    a_pred = y_pred[:, :embedding_size]\n",
        "    p_pred = y_pred[:, embedding_size:ind]\n",
        "    n_pred = y_pred[:, ind:]\n",
        "    if cosine:\n",
        "        positive_distance = 1 - K.sum((a_pred * p_pred), axis=-1)\n",
        "        negative_distance = 1 - K.sum((a_pred * n_pred), axis=-1)\n",
        "    else:\n",
        "        positive_distance = K.sqrt(K.sum(K.square(a_pred - p_pred), axis=-1))\n",
        "        negative_distance = K.sqrt(K.sum(K.square(a_pred - n_pred), axis=-1))\n",
        "    loss = K.maximum(0.0, positive_distance - negative_distance + alpha)\n",
        "    return loss\n",
        "  \n",
        "class TripletImageLoader(Sequence):\n",
        "    def __init__(self, path, img_shape, batchSize = 16, flip=False, examples=2):\n",
        "        self.path = path\n",
        "        self.batchSize = batchSize\n",
        "        self.images = self.load_dataset(path)\n",
        "        self.N = len(self.images[0])\n",
        "        self.shape = img_shape\n",
        "        self.flip = flip\n",
        "        self.examples = examples\n",
        "        \n",
        "    def load_dataset(self, path):\n",
        "        young = []\n",
        "        old = []\n",
        "        \n",
        "        images = sorted(os.listdir(path))\n",
        "        images_total = len(images)\n",
        "        \n",
        "        for i in range(images_total//2):\n",
        "          img_y = path + '/{}'.format(images[2*i])\n",
        "          img_o = path + '/{}'.format(images[2*i+1])\n",
        "          young.append(img_y)\n",
        "          old.append(img_o)\n",
        "          \n",
        "        young = np.asarray(young)\n",
        "        old = np.asarray(old)\n",
        "        return [young, old]\n",
        "      \n",
        "    def load_image(self, file):\n",
        "      img = image.load_img(file)\n",
        "      img = image.img_to_array(img)\n",
        "      if self.flip:\n",
        "          if np.random.randint(0, 2): # do flippings in 50% of the time\n",
        "              img = img[:, ::-1, :]\n",
        "      return img\n",
        "\n",
        "    #gets the number of batches this generator returns\n",
        "    def __len__(self):\n",
        "        l,rem = divmod(self.N, self.batchSize)\n",
        "        return (l + (1 if rem > 0 else 0))\n",
        "    \n",
        "    #shuffles data on epoch end\n",
        "    def on_epoch_end(self):\n",
        "        a = np.arange(len(self.images[0]))\n",
        "        np.random.shuffle(a)\n",
        "        self.images[0]= self.images[0][a] \n",
        "        self.images[1]= self.images[1][a] \n",
        "        \n",
        "    #gets a batch with index = i\n",
        "    def __getitem__(self, i):\n",
        "        n = self.examples\n",
        "        start = i*self.batchSize\n",
        "        stop  = np.min([(i+1)*self.batchSize, self.N]) # clip stop index to be <= N\n",
        "        # Memory preallocation\n",
        "        size = stop-start\n",
        "        ANCHOR = np.zeros( (n*size,) + self.shape + (3,) )\n",
        "        POSITIVE = np.zeros( (n*size,) + self.shape + (3,) )\n",
        "        NEGATIVE = np.zeros( (n*size,) + self.shape + (3,) )\n",
        "        anchor_images = self.images[0][start:stop], self.images[1][start:stop]\n",
        "        pos_images = []\n",
        "        neg_images = []\n",
        "        for k in range(size):\n",
        "          for j in range(n):\n",
        "            try:\n",
        "              ANCHOR[n*k + j] = self.load_image(anchor_images[0][k])\n",
        "              POSITIVE[n*k + j] = self.load_image(anchor_images[1][k])\n",
        "              NEGATIVE[n*k + j] = self.load_image(anchor_images[1][(k+j+1) % size]) \n",
        "            except:\n",
        "              pass\n",
        "\n",
        "\n",
        "        return [ANCHOR, POSITIVE, NEGATIVE], np.empty(n*size) # we don't need labels so we reutrn dummy label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CR9g-Y69zQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "FACE_DEFAULT_SHAPE = (128, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk0TBn3h-Rrc",
        "colab_type": "code",
        "outputId": "57306881-40c0-41f7-ae24-835add0fe579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# Create base model (convolution features extractor)\n",
        "xception = Xception(include_top=False, weights=None, input_shape = FACE_DEFAULT_SHAPE + (3,))\n",
        "output = GlobalAveragePooling2D()(xception.output)\n",
        "base_model = Model(xception.input, output)\n",
        "\n",
        "def embedder(conv_feat_size):\n",
        "    '''\n",
        "    Takes the output of the conv feature extractor and yields the embeddings\n",
        "    '''\n",
        "    input = Input((conv_feat_size,), name = 'input')\n",
        "    normalize = Lambda(lambda x: K.l2_normalize(x, axis=-1), name='normalize')\n",
        "    x = Dense(512)(input)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = normalize(x)\n",
        "    model = Model(input, x)\n",
        "    return model\n",
        "    \n",
        "def get_siamese_model(base_model):\n",
        "    \n",
        "    inp_shape = K.int_shape(base_model.input)[1:]\n",
        "    conv_feat_size = K.int_shape(base_model.output)[-1]\n",
        "    \n",
        "    input_a = Input( inp_shape,  name='anchor')\n",
        "    input_p = Input( inp_shape,  name='positive')\n",
        "    input_n = Input( inp_shape,  name='negative')\n",
        "    emb_model = embedder(conv_feat_size)\n",
        "    output_a = emb_model(base_model(input_a))\n",
        "    output_p = emb_model(base_model(input_p))\n",
        "    output_n = emb_model(base_model(input_n))\n",
        "    \n",
        "    merged_vector = Concatenate(axis=-1)([output_a, output_p, output_n])\n",
        "    model = Model(inputs=[input_a, input_p, input_n],\n",
        "                  outputs=merged_vector)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_siamese_model(base_model)\n",
        "# model.load_weights('siamese_xception.h5')\n",
        "if PARALLEL:\n",
        "    parallel_model = multi_gpu_model(model, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 16:48:47.934749 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0617 16:48:47.953429 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0617 16:48:47.956917 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0617 16:48:47.978048 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0617 16:48:47.979080 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0617 16:48:48.813873 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0617 16:48:49.189585 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejta-ZCA-fCD",
        "colab_type": "code",
        "outputId": "796e952f-7f94-460e-c83e-27fd19a10a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "train_gen = TripletImageLoader('denoised_training', FACE_DEFAULT_SHAPE, batchSize = BATCH_SIZE)\n",
        "valid_gen = TripletImageLoader('denoised_val', FACE_DEFAULT_SHAPE, batchSize = BATCH_SIZE)\n",
        "\n",
        "model.compile(Adam(lr = 0.0001), loss = triplet_loss)\n",
        "\n",
        "checkpoint = ModelCheckpoint('siamese_xception.h5', monitor='val_loss', \n",
        "                             verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "\n",
        "model.fit_generator(train_gen, steps_per_epoch=len(train_gen), \n",
        "                    epochs=5, validation_data=valid_gen, validation_steps=len(valid_gen), callbacks=[checkpoint])\n",
        "# Load best model\n",
        "model.load_weights('siamese_xception.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0617 16:49:00.848264 140075677566848 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0617 16:49:01.011344 140075677566848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "197/197 [==============================] - 98s 496ms/step - loss: 0.1647 - val_loss: 0.1821\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.18211, saving model to siamese_xception.h5\n",
            "Epoch 2/5\n",
            "197/197 [==============================] - 74s 374ms/step - loss: 0.1172 - val_loss: 0.1375\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.18211 to 0.13748, saving model to siamese_xception.h5\n",
            "Epoch 3/5\n",
            "197/197 [==============================] - 74s 375ms/step - loss: 0.1003 - val_loss: 0.1358\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.13748 to 0.13580, saving model to siamese_xception.h5\n",
            "Epoch 4/5\n",
            "197/197 [==============================] - 74s 375ms/step - loss: 0.0862 - val_loss: 0.1570\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.13580\n",
            "Epoch 5/5\n",
            "197/197 [==============================] - 74s 374ms/step - loss: 0.0779 - val_loss: 0.1272\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.13580 to 0.12717, saving model to siamese_xception.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt-if_8GKH7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWeSylCpKwQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('siamese_xception.h5')\n",
        "\n",
        "inp = model.input[0]\n",
        "base_model = model.layers[3]\n",
        "emb_model = model.layers[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LidVQW1MK74L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infer_model = Model(inp, emb_model(base_model(inp)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS1pA7RLK7_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(model, path):\n",
        "  images = sorted(os.listdir(path))\n",
        "  young = []\n",
        "  old = []\n",
        "  for i in range(len(images)//2):\n",
        "    img = image.load_img(os.path.join(path, images[2*i]))\n",
        "    img = image.img_to_array(img)\n",
        "    young_emb = model.predict(img[None])[0]\n",
        "    young.append(young_emb)\n",
        "    img = image.load_img(os.path.join(path, images[2*i+1]))\n",
        "    img = image.img_to_array(img)\n",
        "    old_emb = model.predict(img[None])[0]\n",
        "    old.append(old_emb)\n",
        "  return np.asarray(young), np.asarray(old)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "511yL4koK8B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y, train_o = get_embeddings(infer_model, 'denoised_training')\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/train_y.npy\", train_y)\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/train_o.npy\", train_o)\n",
        "\n",
        "val_y, val_o = get_embeddings(infer_model, 'denoised_val')\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/val_y.npy\", val_y)\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/val_o.npy\", val_o)\n",
        "\n",
        "test_y, test_o = get_embeddings(infer_model, 'denoised_testing')\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/test_y.npy\", test_y)\n",
        "np.save(\"gdrive/My Drive/Colab Notebooks/Patrones/test_o.npy\", test_o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCoRf4giK8D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}